{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!pip install segmentation_models_pytorch   # Install dependencies\n",
    "#!pip install timm\n",
    "#!pip install -U git+https://github.com/albu/albumentations --no-cache-dir\n",
    "#!pip install -U git+https://github.com/albumentations-team/albumentations\n",
    "#!pip install albumentations\n",
    "#!pip install segmentation_models_pytorch\n",
    "import segmentation_models_pytorch as smp\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import albumentations as albu\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset as BaseDataset\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_DIR = './'\n",
    "x_test_dir = 'test1/image'      # Note: put the dataset on the current path.\n",
    "y_test_dir = 'test1/label/'  # You can modify it to test on the 2-80 Additional Original Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\PC\\Anaconda3\\envs\\pytorch2\\lib\\site-packages\\torch\\serialization.py:656: SourceChangeWarning: source code of class 'segmentation_models_pytorch.fpn.model.FPN' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "D:\\Users\\PC\\Anaconda3\\envs\\pytorch2\\lib\\site-packages\\torch\\serialization.py:656: SourceChangeWarning: source code of class 'segmentation_models_pytorch.encoders.senet.SENetEncoder' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "D:\\Users\\PC\\Anaconda3\\envs\\pytorch2\\lib\\site-packages\\torch\\serialization.py:656: SourceChangeWarning: source code of class 'torch.nn.modules.container.Sequential' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "D:\\Users\\PC\\Anaconda3\\envs\\pytorch2\\lib\\site-packages\\torch\\serialization.py:656: SourceChangeWarning: source code of class 'torch.nn.modules.conv.Conv2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "D:\\Users\\PC\\Anaconda3\\envs\\pytorch2\\lib\\site-packages\\torch\\serialization.py:656: SourceChangeWarning: source code of class 'torch.nn.modules.batchnorm.BatchNorm2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "D:\\Users\\PC\\Anaconda3\\envs\\pytorch2\\lib\\site-packages\\torch\\serialization.py:656: SourceChangeWarning: source code of class 'torch.nn.modules.activation.ReLU' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "D:\\Users\\PC\\Anaconda3\\envs\\pytorch2\\lib\\site-packages\\torch\\serialization.py:656: SourceChangeWarning: source code of class 'torch.nn.modules.pooling.MaxPool2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "D:\\Users\\PC\\Anaconda3\\envs\\pytorch2\\lib\\site-packages\\torch\\serialization.py:656: SourceChangeWarning: source code of class 'torch.nn.modules.pooling.AdaptiveAvgPool2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "D:\\Users\\PC\\Anaconda3\\envs\\pytorch2\\lib\\site-packages\\torch\\serialization.py:656: SourceChangeWarning: source code of class 'torch.nn.modules.activation.Sigmoid' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "D:\\Users\\PC\\Anaconda3\\envs\\pytorch2\\lib\\site-packages\\torch\\serialization.py:656: SourceChangeWarning: source code of class 'torch.nn.modules.container.ModuleList' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "D:\\Users\\PC\\Anaconda3\\envs\\pytorch2\\lib\\site-packages\\torch\\serialization.py:656: SourceChangeWarning: source code of class 'torch.nn.modules.normalization.GroupNorm' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "D:\\Users\\PC\\Anaconda3\\envs\\pytorch2\\lib\\site-packages\\torch\\serialization.py:656: SourceChangeWarning: source code of class 'torch.nn.modules.dropout.Dropout2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "D:\\Users\\PC\\Anaconda3\\envs\\pytorch2\\lib\\site-packages\\torch\\serialization.py:656: SourceChangeWarning: source code of class 'torch.nn.modules.upsampling.UpsamplingBilinear2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "D:\\Users\\PC\\Anaconda3\\envs\\pytorch2\\lib\\site-packages\\torch\\serialization.py:656: SourceChangeWarning: source code of class 'segmentation_models_pytorch.base.modules.Activation' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    }
   ],
   "source": [
    "DEVICE = 'cuda'\n",
    "CLASSES = ['crack']\n",
    "ENCODER = 'se_resnext50_32x4d'\n",
    "ENCODER_WEIGHTS = 'imagenet'\n",
    "CLASSES = ['crack']\n",
    "ACTIVATION = 'sigmoid' # could be None for logits or 'softmax2d' for multicalss segmentation\n",
    "# create segmentation model with pretrained encoder\n",
    "preprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)\n",
    "fpn = torch.load('fpn.pth',map_location=DEVICE).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "# get the imread result from test set((3864, 5152, 3)or(3264, 4928, 3) numpy), return numpy of  （98，3，480，640）or（145，3，480，640）\n",
    "def testdataprocessing(img):\n",
    "    h,w,c = img.shape\n",
    "    #padding the images with zeros\n",
    "    if h == 2448:\n",
    "        img = cv2.copyMakeBorder(img , 216, 216, 288 , 288, cv2.BORDER_CONSTANT, value=0)\n",
    "        ##(6*480=2880,6*640=3840)\n",
    "    elif h == 3024:\n",
    "        img = cv2.copyMakeBorder(img,168,168,224 , 224, cv2.BORDER_CONSTANT, value=0)\n",
    "    output = np.zeros([1,480,640,3], dtype=int)\n",
    "     #(7*480=3360,7*640=4480)\n",
    "    h,w,c = img.shape\n",
    "    #set the stride in colomns/rows is 480/640\n",
    "    stride_h = 480\n",
    "    stride_w = 640\n",
    "    if h == 2880:\n",
    "        column = int(h/480)\n",
    "        row = int(w/640)\n",
    "        for i in range(row):\n",
    "            for j in range(column):\n",
    "                term = np.zeros([480,640,3], dtype=int)\n",
    "                term = img[j*stride_h:j*stride_h + stride_h, i*stride_w : i*stride_w+stride_w,:].copy() \n",
    "                term = term[np.newaxis,:,:,:]\n",
    "                output = np.concatenate((output,term),axis = 0)\n",
    "        output = np.delete(output,0,axis = 0)\n",
    "        #get the center part of raw images and split again\n",
    "        img_seg = img[240:2640,320:3520,:].copy()\n",
    "        for i in range(row-1):\n",
    "            for j in range(column-1):\n",
    "                term = np.zeros([480,640,3], dtype=int)\n",
    "                term = img_seg[j*stride_h:j*stride_h + stride_h, i*stride_w : i*stride_w+stride_w,:].copy() \n",
    "                term = term[np.newaxis,:,:,:]\n",
    "                output = np.concatenate((output,term),axis = 0)\n",
    "\n",
    "    if h == 3360:\n",
    "        column = int(h/480)\n",
    "        row = int(w/640)\n",
    "        for i in range(row):\n",
    "            for j in range(column):\n",
    "                term = np.zeros([480,640,3], dtype=int)\n",
    "                term = img[j*stride_h:j*stride_h + stride_h, i*stride_w : i*stride_w+stride_w,:].copy() \n",
    "                term = term[np.newaxis,:,:,:]\n",
    "                output = np.concatenate((output,term),axis = 0)\n",
    "        output = np.delete(output,0,axis = 0)\n",
    "        #get the center part of raw images and split again\n",
    "        img_seg = img[240:3120,320:4160,:].copy()\n",
    "        for i in range(row-1):\n",
    "            for j in range(column-1):\n",
    "                term = np.zeros([480,640,3], dtype=int)\n",
    "                term = img_seg[j*stride_h:j*stride_h + stride_h, i*stride_w : i*stride_w+stride_w,:].copy() \n",
    "                term = term[np.newaxis,:,:,:]\n",
    "                output = np.concatenate((output,term),axis = 0)\n",
    "    return output\n",
    "\n",
    "#trainsofrm the numpy of （98，480，640）/（145，480，640）back into (3864，5152）or（3264，4928）\n",
    "def visualizaion(output):\n",
    "    n,stride_h,stride_w = output.shape    \n",
    "    if n == 61:\n",
    "        count = 0\n",
    "        #combine the firt part of predition\n",
    "        mask_1 = np.zeros([2880,3840], dtype=int)\n",
    "        for i in range (6):\n",
    "            for j in range(6):\n",
    "                mask_1[j*stride_h:j*stride_h + stride_h, i*stride_w : i*stride_w+stride_w] = output[count,:,:].copy()  \n",
    "                count += 1\n",
    "        mask_2 = np.zeros([2400,3200], dtype=int)     \n",
    "        #combine the second part of prediction\n",
    "        for i in range (5):\n",
    "            for j in range(5):\n",
    "                mask_2[j*stride_h:j*stride_h + stride_h, i*stride_w : i*stride_w+stride_w] = output[count,:,:].copy()  \n",
    "                count += 1     \n",
    "        #sum the mask1 and mask2 in pixel level\n",
    "        mask_3 = mask_1[240:2640,320:3520].copy() + mask_2[:,:].copy()\n",
    "        mask_3 = mask_3*0.5\n",
    "        prediction = mask_1.copy()\n",
    "        prediction[240:2640,320:3520] = mask_3[:,:]\n",
    "        p = prediction[216:2664,288:3552].copy()    \n",
    "    if n == 85:\n",
    "        count = 0\n",
    "        #combine the first part of prediction\n",
    "        mask_1 = np.zeros([3360,4480], dtype=int)\n",
    "        for i in range (7):\n",
    "            for j in range(7):\n",
    "                mask_1[j*stride_h:j*stride_h + stride_h, i*stride_w : i*stride_w+stride_w] = output[count,:,:].copy()  \n",
    "                count += 1\n",
    "        mask_2 = np.zeros([2880,3840], dtype=int) \n",
    "        #combine the second part of prediction\n",
    "        for i in range (6):\n",
    "            for j in range(6):\n",
    "                mask_2[j*stride_h:j*stride_h + stride_h, i*stride_w : i*stride_w+stride_w] = output[count,:,:].copy()  \n",
    "                count += 1 \n",
    "        #sum the mask1 and mask2 in pixel level\n",
    "        mask_3 = mask_1[240:3120,320:4160].copy() + mask_2[:,:].copy()\n",
    "        mask_3 = mask_3*0.5\n",
    "        prediction = mask_1.copy()\n",
    "        prediction[240:3120,320:4160] = mask_3[:,:]\n",
    "        p = prediction[168:3192,224:4256].copy()        \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "# get the imread result from test set((3864, 5152, 3)or(3264, 4928, 3) numpy), return numpy of  （98，3，480，640）or（145，3，480，640）\n",
    "def testdataprocessing(img):\n",
    "    output = np.zeros([1,320,320,3], dtype=int)\n",
    "    term = img[np.newaxis,:,:,:]\n",
    "    output = np.concatenate((output,term),axis = 0)\n",
    "    print(output.shape)\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def visualizaion(output):\n",
    "    n,stride_h,stride_w = output.shape    \n",
    "    \n",
    "    mask = np.zeros([320,320], dtype=int)\n",
    "    mask[:,:] = output[1,:,:].copy()         \n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the dataset\n",
    "class Dataset(BaseDataset):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        images_dir (str): path to images folder\n",
    "        masks_dir (str): path to segmentation masks folder\n",
    "        class_values (list): values of classes to extract from segmentation mask\n",
    "        augmentation (albumentations.Compose): data transfromation pipeline \n",
    "            (e.g. flip, scale, etc.)\n",
    "        preprocessing (albumentations.Compose): data preprocessing \n",
    "            (e.g. noralization, shape manipulation, etc.)\n",
    "    Note: we don't need mask when testing.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    CLASSES = ['crack']\n",
    "    \n",
    "    def __init__(\n",
    "            self, \n",
    "            images_dir, \n",
    "            classes=None, \n",
    "            augmentation=None, \n",
    "            preprocessing=None,\n",
    "    ):\n",
    "        self.ids = sorted(os.listdir(images_dir))\n",
    "        #将image文件夹下的所有照片名称创建为一个列表并且顺序排列['001.png','002.png'.....]\n",
    "        self.images_fps = [os.path.join(images_dir, image_id) for image_id in self.ids]\n",
    "        #将所有照片路径创建为列表['test1/image\\\\0001.png','test1/image\\\\0002.png'...]\n",
    "        \n",
    "        # convert str names to class values on masks名称变成值？\n",
    "        self.class_values = [self.CLASSES.index(cls.lower()) for cls in classes]\n",
    "        \n",
    "        self.augmentation = augmentation\n",
    "        self.preprocessing = preprocessing\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        \n",
    "        # read data\n",
    "        image = cv2.imread(self.images_fps[i],1)\n",
    "        #1加载彩色，0加载灰度，-1还读入alpha通道代表透明度\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        #opencv默认通道是bgr，这是早期留下来的问题。因此将bgr转换为rgb\n",
    "        # apply augmentations\n",
    "        if self.augmentation:\n",
    "            sample = self.augmentation(image=image)\n",
    "            image = sample['image']\n",
    "        if self.preprocessing:\n",
    "            sample = self.preprocessing(image=image)\n",
    "            image = sample['image']\n",
    "        image = testdataprocessing(image.transpose(1,2,0))\n",
    "        image = image.transpose(0,3,1,2)\n",
    "        return image\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "    #暂时不知道什么用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create test dataset\n",
    "def get_validation_augmentation():\n",
    "    \"\"\"You can put some augmentations on here\"\"\"\n",
    "    #可以加入不同的操作，只需放在test_transform列表里。Resize可以不改变照片内容，改变图片像素尺寸\n",
    "    test_transform = [\n",
    "     albu.Resize(320,320),\n",
    "    ]\n",
    "    return albu.Compose(test_transform)\n",
    "    #就是将所有操作打包起来，对对象操作时：image3=albu.Compose(test_transform)(image=image_name)['image']\n",
    "def to_tensor(x, **kwargs):\n",
    "    return x.transpose(2, 0, 1).astype('float32')\n",
    "def get_preprocessing(preprocessing_fn):\n",
    "    \"\"\"Construct preprocessing transform\n",
    "    \n",
    "    Args:\n",
    "        preprocessing_fn (callbale): data normalization function \n",
    "            (can be specific for each pretrained neural network)\n",
    "    Return:\n",
    "        transform: albumentations.Compose\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    _transform = [\n",
    "        albu.Lambda(image=preprocessing_fn),\n",
    "        albu.Lambda(image=to_tensor),\n",
    "    ]\n",
    "    return albu.Compose(_transform)\n",
    "    \n",
    "test_dataset = Dataset(\n",
    "    x_test_dir, \n",
    "    augmentation=None, # for test, we just set augmentation to None\n",
    "    preprocessing=get_preprocessing(preprocessing_fn),\n",
    "    classes=CLASSES,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(2, 320, 320, 3)\n",
      "1\n",
      "(2, 320, 320, 3)\n",
      "2\n",
      "(2, 320, 320, 3)\n",
      "3\n",
      "(2, 320, 320, 3)\n",
      "4\n",
      "(2, 320, 320, 3)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "pre_1 = []\n",
    "os.system('mkdir Demo')\n",
    "# output mask\n",
    "for n in range(len(test_dataset)):\n",
    "    print(n)\n",
    "    image = test_dataset[n]\n",
    "    x_tensor = torch.FloatTensor(image).to(DEVICE)\n",
    "    shape = x_tensor.shape[0]//3    # reduce memory on GPU\n",
    "    pr_mask = []\n",
    "    with torch.no_grad():\n",
    "        mask = fpn.predict(x_tensor).squeeze().detach().cpu().numpy().round()\n",
    "        pr_mask.append(mask)\n",
    "#         mask = fpn.predict(x_tensor[shape:shape*2]).squeeze().detach().cpu().numpy().round()\n",
    "#         pr_mask.append(mask)\n",
    "#         mask = fpn.predict(x_tensor[shape*2:]).squeeze().detach().cpu().numpy().round()\n",
    "#         pr_mask.append(mask)\n",
    "    pr_mask = np.concatenate(np.array(pr_mask),axis=0)  # concatenate three pieces\n",
    "    pr_mask= visualizaion(pr_mask)\n",
    "    pr_mask[pr_mask > 0]=1\n",
    "    pre_1.append(pr_mask)\n",
    "    matplotlib.image.imsave(\"Demo2/%04.d.png\"%(n+1), pr_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : 0.5852\n",
      "2 : 0.5167\n",
      "3 : 0.5706\n",
      "4 : 0.6068\n",
      "5 : 0.6344\n",
      "6 : 0.8475\n",
      "7 : 0.8503\n",
      "8 : 0.8307\n",
      "9 : 0.8206\n",
      "10 : 0.8184\n",
      "11 : 0.7651\n",
      "12 : 0.8063\n",
      "13 : 0.7736\n",
      "14 : 0.6648\n",
      "15 : 0.8392\n",
      "16 : 0.8998\n",
      "17 : 0.8346\n",
      "18 : 0.7713\n",
      "19 : 0.8126\n",
      "20 : 0.8326\n",
      "Final miou: 0.7540582825979366\n"
     ]
    }
   ],
   "source": [
    "# calculate iou\n",
    "data = []\n",
    "for j,i in enumerate(sorted(os.listdir(x_test_dir))):\n",
    "    mask_1 = cv2.imread(\"Demo/\"+i,0)\n",
    "    mask_1[mask_1==30]=0\n",
    "    mask_1[mask_1==215]=1\n",
    "    mask_2 = cv2.imread(y_test_dir+i, 0)\n",
    "    mask_2[mask_2>0]=1\n",
    "    mask_3 = mask_1 & mask_2\n",
    "    mask_2[mask_1>0]=1\n",
    "    iou = mask_3.sum()/mask_2.sum()\n",
    "    print(str(j+1),':',\"%.4f\" % (iou))\n",
    "    data.append(iou)\n",
    "print(\"Final miou:\", np.mean(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-0467bd1300bf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfpn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m320\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m320\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Users\\PC\\Anaconda3\\envs\\pytorch2\\lib\\site-packages\\torchsummary\\torchsummary.py\u001b[0m in \u001b[0;36msummary\u001b[1;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[1;31m# make a forward pass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[1;31m# print(x.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[1;31m# remove these hooks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\PC\\Anaconda3\\envs\\pytorch2\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\PC\\Anaconda3\\envs\\pytorch2\\lib\\site-packages\\segmentation_models_pytorch\\base\\model.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;34m\"\"\"Sequentially pass `x` trough model`s encoder, decoder and heads\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mdecoder_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mmasks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msegmentation_head\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecoder_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\PC\\Anaconda3\\envs\\pytorch2\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\PC\\Anaconda3\\envs\\pytorch2\\lib\\site-packages\\segmentation_models_pytorch\\fpn\\decoder.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, *features)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[0mfeature_pyramid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mseg_block\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mseg_block\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseg_blocks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mp5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_pyramid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\PC\\Anaconda3\\envs\\pytorch2\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    892\u001b[0m                 self._forward_hooks.values()):\n\u001b[1;32m--> 893\u001b[1;33m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    894\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhook_result\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    895\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\PC\\Anaconda3\\envs\\pytorch2\\lib\\site-packages\\torchsummary\\torchsummary.py\u001b[0m in \u001b[0;36mhook\u001b[1;34m(module, input, output)\u001b[0m\n\u001b[0;32m     21\u001b[0m                 \u001b[0msummary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mm_key\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"input_shape\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m                \u001b[0msummary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mm_key\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"input_shape\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m             \u001b[1;31m#修改end here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[1;31m#summary[m_key][\"input_shape\"] = list(input[0].size())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'int' object is not callable"
     ]
    }
   ],
   "source": [
    "summary(fpn,(3,320, 320))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPN(\n",
      "  (encoder): SENetEncoder(\n",
      "    (layer0): Sequential(\n",
      "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (pool): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "    )\n",
      "    (layer1): Sequential(\n",
      "      (0): SEResNeXtBottleneck(\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (se_module): SEModule(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): SEResNeXtBottleneck(\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (se_module): SEModule(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "      (2): SEResNeXtBottleneck(\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (se_module): SEModule(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): SEResNeXtBottleneck(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (se_module): SEModule(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): SEResNeXtBottleneck(\n",
      "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (se_module): SEModule(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "      (2): SEResNeXtBottleneck(\n",
      "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (se_module): SEModule(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "      (3): SEResNeXtBottleneck(\n",
      "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (se_module): SEModule(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): SEResNeXtBottleneck(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (se_module): SEModule(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): SEResNeXtBottleneck(\n",
      "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (se_module): SEModule(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "      (2): SEResNeXtBottleneck(\n",
      "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (se_module): SEModule(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "      (3): SEResNeXtBottleneck(\n",
      "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (se_module): SEModule(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "      (4): SEResNeXtBottleneck(\n",
      "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (se_module): SEModule(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "      (5): SEResNeXtBottleneck(\n",
      "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (se_module): SEModule(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (fc2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): SEResNeXtBottleneck(\n",
      "        (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (se_module): SEModule(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (fc2): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): SEResNeXtBottleneck(\n",
      "        (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (se_module): SEModule(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (fc2): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "      (2): SEResNeXtBottleneck(\n",
      "        (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (se_module): SEModule(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (fc2): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): FPNDecoder(\n",
      "    (p5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (p4): FPNBlock(\n",
      "      (skip_conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (p3): FPNBlock(\n",
      "      (skip_conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (p2): FPNBlock(\n",
      "      (skip_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (seg_blocks): ModuleList(\n",
      "      (0): SegmentationBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Conv3x3GNReLU(\n",
      "            (block): Sequential(\n",
      "              (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (1): Conv3x3GNReLU(\n",
      "            (block): Sequential(\n",
      "              (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (2): Conv3x3GNReLU(\n",
      "            (block): Sequential(\n",
      "              (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): SegmentationBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Conv3x3GNReLU(\n",
      "            (block): Sequential(\n",
      "              (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (1): Conv3x3GNReLU(\n",
      "            (block): Sequential(\n",
      "              (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (2): SegmentationBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Conv3x3GNReLU(\n",
      "            (block): Sequential(\n",
      "              (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (3): SegmentationBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Conv3x3GNReLU(\n",
      "            (block): Sequential(\n",
      "              (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "              (2): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (merge): MergeBlock()\n",
      "    (dropout): Dropout2d(p=0.2, inplace=True)\n",
      "  )\n",
      "  (segmentation_head): SegmentationHead(\n",
      "    (0): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): UpsamplingBilinear2d(scale_factor=4.0, mode=bilinear)\n",
      "    (2): Activation(\n",
      "      (activation): Sigmoid()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch2]",
   "language": "python",
   "name": "conda-env-pytorch2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
